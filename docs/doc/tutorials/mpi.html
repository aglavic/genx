
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Using GenX from the command line (with mpi) &#8212; GenX 3.8.5 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/classic.css" />
    
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    
    <link rel="shortcut icon" href="../_static/genx.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Running GenX Models in Jupyter Notebook/Lab" href="notebook.html" />
    <link rel="prev" title="Optimizer and model performance" href="performance.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="notebook.html" title="Running GenX Models in Jupyter Notebook/Lab"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="performance.html" title="Optimizer and model performance"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">GenX 3.8.5 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../tutorials.html" accesskey="U">Tutorials</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Using GenX from the command line (with mpi)</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="using-genx-from-the-command-line-with-mpi">
<span id="tutorial-mpi"></span><h1>Using GenX from the command line (with mpi)<a class="headerlink" href="#using-genx-from-the-command-line-with-mpi" title="Permalink to this headline">¶</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Using GenX from the command line lets you, in the simplest case, start up the gui. You can also
run fits without starting up the gui at all. This opens possibilities to make a batch script of multiple GenX runs and,
in addition, you can run GenX on machines without a desktop environment. GenX also supports mpi for fitting
in parallel opens up the possibility to use it on clusters. The mpi implementation was contributed by Canrong Qiu.
Note that, currently, the command line is only fully implemented in the source/pip versions.</p>
</section>
<section id="dependencies">
<h2>Dependencies<a class="headerlink" href="#dependencies" title="Permalink to this headline">¶</a></h2>
<p>If you only intend to run GenX from the command line you do not need an installation of wxPython or matplotlib.</p>
<p>See section <a class="reference internal" href="../install.html#install-cluster"><span class="std std-ref">Clusters</span></a> for installation instructions.</p>
</section>
<section id="command-line-arguments">
<h2>Command line arguments<a class="headerlink" href="#command-line-arguments" title="Permalink to this headline">¶</a></h2>
<p>The arguments to GenX can be viewed by executing the program with the <code class="docutils literal notranslate"><span class="pre">--help</span></code> option.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All commands should work from the source folder without installation by using <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">scripts/genx</span></code> as execuable.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ genx --help
usage: genx [-h] [-r | --mpi | -g | --pars | --mod]
            [--pr PR] [--cs CS] [--mgen MGEN] [--pops POPS] [--asi ASI] [--km KM] [--kr KR]
            [-s] [-e] [--var VAR] [--bumps]
            [-d DATA_SET] [--load DATAFILE] [--export SAVE_DATAFILE]
            [-l LOGFILE] [--debug] [--dpi-scale DPI_OVERWRITE] [--no-curses] [--disable-nb] [--nb1]
            [infile] [outfile]

GenX 3.6.0, fits data to a model.

positional arguments:
  infile                The .gx or .hgx file to load or .ort file to use as basis for model
  outfile               The .gx or hgx file to save into

optional arguments:
  -h, --help            show this help message and exit
  -r, --run             run GenX fit (no gui)
  --mpi                 run GenX fit with mpi (no gui)
  -g, --gen             generate data.y with poisson noise added (no gui)
  --pars                extract the parameters from the infile (no gui)
  --mod                 modify the GenX file (no gui)

optimization arguments:
  --pr PR               Number of processes used in parallel fitting.
  --cs CS               Chunk size used for parallel processing.
  --mgen MGEN           Maximum number of generations that is used in a fit
  --pops POPS           Population size - number of individuals.
  --asi ASI             Auto save interval (generations).
  --km KM               Mutation constant (float 0 &lt; km &lt; 1)
  --kr KR               Cross over constant (float 0 &lt; kr &lt; 1)
  -s, --esave           Force save evals to gx file.
  -e, --error           Calculate error bars before saving to file.
  --var VAR             Minimum relative parameter variation to stop the fit (%)
  --bumps               Use Bumps DREAM optimizer instead of GenX Differential Evolution

data arguments:
  -d DATA_SET           Active data set to act upon. Index starting at 0.
  --load DATAFILE       Load file into active data set. Index starting at 0.
  --export SAVE_DATAFILE
                        Save active data set to file. Index starting at 0.

startup options:
  -l LOGFILE, --logfile LOGFILE
                        Output debug information to logfile.
  --debug               Show additional debug information on console/logfile
  --dpi-scale DPI_OVERWRITE
                        Overwrite the detection of screen dpi scaling factor (=72/dpi)
  --no-curses           Disable Curses interactive console interface for command line fitting on UNIX systems.
  --disable-nb          Disable the use of numba JIT compiler
  --nb1                 Compile numba JIT functions without parallel computing support (use one core only).
                        This does disable caching to prevent parallel versions from being loaded.

For support, manuals and bug reporting see http://genx.sf.net
</pre></div>
</div>
<p>To run a fit using the multiprocessing module (forking different processes) which is the same code as in the gui
the following command can be executed.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ python ./scripts/genx --run --mgen=10 --pr 8 ./genx/examples/X-ray_Reflectivity.hgx test.hgx
INFO: *** GenX 3.6.0 Logging started ***
INFO: Loading model C:\Users\Artur\genx\genx\genx\examples\X-ray_Reflectivity.hgx...
INFO: Simulating model...
INFO: Setting up the optimizer...
INFO: DiffEv Optimizer:
 Fitting:
     use_start_guess=True    use_boundaries=True
     use_autosave=False      autosave_interval=10
     save_all_evals=False    max_log_elements=100000
 Differential Evolution:
     km                             0.6
     kr                             0.6
     create_trial                   best_1_bin
     use_pop_mult=False      pop_mult=3      pop_size=50
     use_max_generations=True        max_generations=10      max_generation_mult=6
     min_parameter_spread           0.0
 Parallel processing:
     use_parallel_processing        True
     parallel_processes             8
     parallel_chunksize             1

INFO: Saving the initial model to C:\Users\Artur\genx\genx\test.hgx
INFO: Fitting starting...
INFO: DE initilized
INFO: Setting up a pool of workers ...
INFO: Starting the fit...
INFO: Starting a pool with 8 workers ...
INFO: Calculating start FOM ...
INFO: Going into optimization ...
INFO: FOM: 0.321 Generation: 1 Speed: 2777.7
INFO: FOM: 0.293 Generation: 2 Speed: 2500.0
INFO: FOM: 0.254 Generation: 3 Speed: 2500.2
INFO: FOM: 0.217 Generation: 4 Speed: 2499.9
INFO: FOM: 0.217 Generation: 5 Speed: 2777.7
INFO: FOM: 0.217 Generation: 6 Speed: 2941.2
INFO: FOM: 0.217 Generation: 7 Speed: 2941.2
INFO: FOM: 0.206 Generation: 8 Speed: 2941.3
INFO: FOM: 0.206 Generation: 9 Speed: 3124.8
INFO: FOM: 0.206 Generation: 10 Speed: 2941.3
INFO: Stopped at Generation: 10 after 500 fom evaluations...
INFO: Fitting finished!
INFO: Time to fit:  0.05453455845514933  min
INFO: Updating the parameters
INFO: Saving the fit to C:\Users\Artur\genx\genx\test.hgx
INFO: Fitting successfully completed
INFO: *** GenX 3.6.0 Logging ended ***
</pre></div>
</div>
<p>As can be seen this loads the file <code class="docutils literal notranslate"><span class="pre">.genx/examples/X-ray_Reflectivity.hgx</span></code> sets the maximum number of generation to run
to 10 and then runs the fit. The result is saved to <code class="docutils literal notranslate"><span class="pre">test.hgx</span></code>. Note that to be able to analyse the fits (calculate error bars
for example) the option <code class="docutils literal notranslate"><span class="pre">--esave</span></code> should be used. If the fits take a long time to run it is advisable to save them
every now and then with the <code class="docutils literal notranslate"><span class="pre">--asi</span></code> command that specifies how often the current result should be written to file.
It can also be good idea to directly calculate the errorbars before saving to file with the <code class="docutils literal notranslate"><span class="pre">-e</span></code> command.
Another point to see is that there is a significant speed-up when only using the command line. This is probably due to
that the GUI does not have to be updated.</p>
<p>For UNIX systems the default command line output uses the curses library to better visualize the progress,
the output during refinement will look something like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>   <span class="n">FOM</span><span class="p">:</span> <span class="mf">0.051</span> <span class="n">Generation</span><span class="p">:</span> <span class="mi">25</span> <span class="n">Speed</span><span class="p">:</span> <span class="mf">2162.7</span>
   <span class="n">FOM</span><span class="p">:</span> <span class="mf">0.046</span> <span class="n">Generation</span><span class="p">:</span> <span class="mi">26</span> <span class="n">Speed</span><span class="p">:</span> <span class="mf">2141.1</span>
   <span class="n">FOM</span><span class="p">:</span> <span class="mf">0.046</span> <span class="n">Generation</span><span class="p">:</span> <span class="mi">27</span> <span class="n">Speed</span><span class="p">:</span> <span class="mf">2123.3</span>
   <span class="n">FOM</span><span class="p">:</span> <span class="mf">0.046</span> <span class="n">Generation</span><span class="p">:</span> <span class="mi">28</span> <span class="n">Speed</span><span class="p">:</span> <span class="mf">2120.4</span>
   <span class="n">FOM</span><span class="p">:</span> <span class="mf">0.046</span> <span class="n">Generation</span><span class="p">:</span> <span class="mi">29</span> <span class="n">Speed</span><span class="p">:</span> <span class="mf">1865.8</span>
   <span class="n">FOM</span><span class="p">:</span> <span class="mf">0.046</span> <span class="n">Generation</span><span class="p">:</span> <span class="mi">30</span> <span class="n">Speed</span><span class="p">:</span> <span class="mf">2185.8</span>
   <span class="n">FOM</span><span class="p">:</span> <span class="mf">0.046</span> <span class="n">Generation</span><span class="p">:</span> <span class="mi">31</span> <span class="n">Speed</span><span class="p">:</span> <span class="mf">2176.6</span>
   <span class="n">FOM</span><span class="p">:</span> <span class="mf">0.046</span> <span class="n">Generation</span><span class="p">:</span> <span class="mi">32</span> <span class="n">Speed</span><span class="p">:</span> <span class="mf">2227.9</span>

                               <span class="n">Relative</span> <span class="n">value</span> <span class="ow">and</span> <span class="n">spread</span> <span class="n">of</span> <span class="n">fit</span> <span class="n">parameters</span><span class="p">:</span>                     <span class="n">best</span><span class="o">/</span><span class="n">width</span>
<span class="n">Parameter</span> <span class="mi">00</span><span class="p">:</span> <span class="p">[</span>                                        <span class="o">==</span><span class="c1">#                                     ] 0.53/0.03</span>
<span class="n">Parameter</span> <span class="mi">01</span><span class="p">:</span> <span class="p">[</span>       <span class="o">===================</span><span class="c1">#====================                                 ] 0.34/0.51</span>
<span class="n">Parameter</span> <span class="mi">02</span><span class="p">:</span> <span class="p">[</span>                                 <span class="o">==========================================</span><span class="c1">#=== ] 0.94/0.58</span>
<span class="n">Parameter</span> <span class="mi">03</span><span class="p">:</span> <span class="p">[</span>                      <span class="o">=============================</span><span class="c1">#===================         ] 0.64/0.62</span>
<span class="n">Parameter</span> <span class="mi">04</span><span class="p">:</span> <span class="p">[</span>                                                    <span class="o">=======================</span><span class="c1">#==  ] 0.94/0.33</span>
<span class="n">Parameter</span> <span class="mi">05</span><span class="p">:</span> <span class="p">[</span> <span class="o">=========================</span><span class="c1">#=====================                                ] 0.33/0.59</span>
<span class="n">Parameter</span> <span class="mi">06</span><span class="p">:</span> <span class="p">[</span>                    <span class="o">=============</span><span class="c1">#==========                                    ] 0.42/0.31</span>
<span class="n">Parameter</span> <span class="mi">07</span><span class="p">:</span> <span class="p">[</span>                                              <span class="o">=================</span><span class="c1">#======          ] 0.79/0.31</span>
<span class="n">Parameter</span> <span class="mi">08</span><span class="p">:</span> <span class="p">[</span> <span class="o">============</span><span class="c1">#=================                                                 ] 0.17/0.38</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The fit can be stopped before the breaking conditions using <code class="docutils literal notranslate"><span class="pre">q</span></code>. To deactivate the interactive
view use the <code class="docutils literal notranslate"><span class="pre">--no-curses</span></code> option.</p>
<p>Stopping with q only works on UNIX without curses if <code class="docutils literal notranslate"><span class="pre">&lt;enter&gt;</span></code> is pressed afterwords. This can
also be used to stop a MPI refinement at any time.</p>
</div>
</section>
<section id="using-mpi">
<h2>Using MPI<a class="headerlink" href="#using-mpi" title="Permalink to this headline">¶</a></h2>
<p>If MPI and mpi4py is installed on the system the <code class="docutils literal notranslate"><span class="pre">--mpi</span></code> switch will be activated. Note that the description for
<code class="docutils literal notranslate"><span class="pre">--mpi</span></code> in the help will not appear until the mpi4py can be loaded correctly. In order to use mpi the command <code class="docutils literal notranslate"><span class="pre">mpirun</span></code>
or <code class="docutils literal notranslate"><span class="pre">mpiexec</span></code> has to be used. The argument <code class="docutils literal notranslate"><span class="pre">-np</span></code> defines how many processes to use. An example can be seen below.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ mpirun -np 2 python -m genx.run --mpi --mgen=10 ./genx/examples/X-ray_Reflectivity.hgx test.hgx
INFO: *** GenX 3.6.0 Logging started ***
INFO: Loading model /mnt/c/Users/Artur/genx/genx/genx/examples/X-ray_Reflectivity.hgx...
INFO: Simulating model...
INFO: Setting up the optimizer...
INFO: DiffEv Optimizer:
 Fitting:
     use_start_guess=True    use_boundaries=True
     use_autosave=False      autosave_interval=10
     save_all_evals=False    max_log_elements=100000
 Differential Evolution:
     km                             0.6
     kr                             0.6
     create_trial                   best_1_bin
     use_pop_mult=False      pop_mult=3      pop_size=50
     use_max_generations=True        max_generations=10      max_generation_mult=6
     min_parameter_spread           0.0
 Parallel processing:
     use_parallel_processing        False
     parallel_processes             2
     parallel_chunksize             1

INFO: Saving the initial model to /mnt/c/Users/Artur/genx/genx/test.hgx
INFO: Fitting starting...
INFO: DE initilized
INFO: Inits mpi with 2 processes ...
INFO: Starting the fit...
INFO: Calculating start FOM ...
INFO: Going into optimization ...
INFO: FOM: 0.301 Generation: 1 Speed: 1244.8
INFO: FOM: 0.234 Generation: 2 Speed: 1262.8
INFO: FOM: 0.234 Generation: 3 Speed: 1225.5
INFO: FOM: 0.234 Generation: 4 Speed: 1229.7
INFO: FOM: 0.234 Generation: 5 Speed: 1148.9
INFO: FOM: 0.234 Generation: 6 Speed: 1226.7
INFO: FOM: 0.234 Generation: 7 Speed: 1112.0
INFO: FOM: 0.234 Generation: 8 Speed: 1214.3
INFO: FOM: 0.234 Generation: 9 Speed: 1200.5
INFO: FOM: 0.234 Generation: 10 Speed: 1000.2
INFO: Stopped at Generation: 10 after 500 fom evaluations...
INFO: Fitting finished!
INFO: Time to fit:  0.011236679553985596  min
INFO: Updating the parameters
INFO: Saving the fit to /mnt/c/Users/Artur/genx/genx/test.hgx
INFO: Fitting successfully completed
INFO: *** GenX 3.6.0 Logging ended ***
</pre></div>
</div>
<p>As MPI defines its process externally and the code calculates the chunk size automatically the arguments <code class="docutils literal notranslate"><span class="pre">-pr</span></code> and
<code class="docutils literal notranslate"><span class="pre">--cr</span></code> will not be used in this case. This should be the only changes compared to using it from the command line as
usual.
If a logfile is written with the <code class="docutils literal notranslate"><span class="pre">-l</span></code> option the MPI process number will be added to the file name with the
primary process starting with number <code class="docutils literal notranslate"><span class="pre">00</span></code>.</p>
</section>
<section id="using-remote-refinement-server">
<h2>Using remote refinement server<a class="headerlink" href="#using-remote-refinement-server" title="Permalink to this headline">¶</a></h2>
<p>To have the advantage of high performance computing and interactive refinement GenX has a server script that
can be started on the cluster and a desktop client within the same network can use this as worker for
refinement from a GUI client.</p>
<p>To start the server with the standard parameters run the genx_server command or execute with python directly:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ genx_server
INFO: *** GenX 3.6.0 Logging started ***
INFO: Importing numba based modules to pre-compile JIT functions, this can take some time
INFO: Modules imported successfully
INFO: Starting RemoteController
INFO: Starting listening on localhost with port=3000
</pre></div>
</div>
<p>The fitting is then started from the GUI client selecting the “Remote DiffEv” optimizer. The configuration is done
the same way as for the standard optimizer with additional options for the server configuration.
From the client side the fit should look like a local run refinement and the server outputs a short information
on the console (if –debug is not set).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">INFO</span><span class="p">:</span> <span class="n">Setting</span> <span class="n">a</span> <span class="n">new</span> <span class="n">model</span>
<span class="n">INFO</span><span class="p">:</span> <span class="n">Start</span> <span class="n">fit</span> <span class="n">was</span> <span class="n">triggered</span>
<span class="n">INFO</span><span class="p">:</span> <span class="n">Stop</span> <span class="n">fit</span> <span class="n">was</span> <span class="n">triggered</span>
</pre></div>
</div>
<p>It is also possible to use MPI on the server by starting it using <code class="docutils literal notranslate"><span class="pre">mpiexec</span></code> or <code class="docutils literal notranslate"><span class="pre">mpirun</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mpiexec</span> <span class="o">-</span><span class="n">np</span> <span class="mi">32</span> <span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">genx</span><span class="o">.</span><span class="n">server</span>
</pre></div>
</div>
<p>The client optimizer settings will determine if multiprocessing or MPI will be used.</p>
<section id="connection-settings">
<h3>Connection settings<a class="headerlink" href="#connection-settings" title="Permalink to this headline">¶</a></h3>
<p>The genx_server script takes two optional arguments <code class="docutils literal notranslate"><span class="pre">address</span></code> and <code class="docutils literal notranslate"><span class="pre">port</span></code>. By default the sever listens only to
connections from <strong>localhost</strong> on port <strong>3000</strong>.
You can choose to listen on any incoming network interfaces by supplying <strong>0.0.0.0</strong> as <code class="docutils literal notranslate"><span class="pre">address</span></code> but this is
not very secure as anyone on the local network would be able to connect to this client.
The communication protocol does use a simple password authentication but communication is not encrypted so
it is adviced to keep the port open only locally and using ssh tunnel (-L option) to connect from you machine.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ssh -L 3000:localhost:3000 {server_with_genx}
$ mpiexec -np 32 genx_server
</pre></div>
</div>
</section>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/logo.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Using GenX from the command line (with mpi)</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#dependencies">Dependencies</a></li>
<li><a class="reference internal" href="#command-line-arguments">Command line arguments</a></li>
<li><a class="reference internal" href="#using-mpi">Using MPI</a></li>
<li><a class="reference internal" href="#using-remote-refinement-server">Using remote refinement server</a><ul>
<li><a class="reference internal" href="#connection-settings">Connection settings</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="performance.html"
                        title="previous chapter">Optimizer and model performance</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="notebook.html"
                        title="next chapter">Running GenX Models in Jupyter Notebook/Lab</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/tutorials/mpi.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="notebook.html" title="Running GenX Models in Jupyter Notebook/Lab"
             >next</a> |</li>
        <li class="right" >
          <a href="performance.html" title="Optimizer and model performance"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">GenX 3.8.5 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../tutorials.html" >Tutorials</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Using GenX from the command line (with mpi)</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2014, Matts Björck, 2020, Artur Glavic.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.3.2.
    </div>
  </body>
</html>